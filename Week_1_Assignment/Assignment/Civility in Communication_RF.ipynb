{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Civility in Communication\n",
    "\n",
    "The focus of this assignment will be on a) training a classifier to perform hate speech detection; b) use LIME to explain the classifier's behaviour; c) establish whether the classifier might be biased wrt. different demographic dialects.\n",
    "\n",
    "This assignment is divided into three parts:\n",
    "1. **Before the laboratory** (individually): read [LIME's paper](https://arxiv.org/abs/1602.04938) and understand how its Python implementation works: https://github.com/marcotcr/lime (docs: https://lime-ml.readthedocs.io/en/latest/index.html). Check these tutorials in particular: [1](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html) and [2](https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html). Furthermore, download the dataset, read its description below and make sure you understand it. Finally, implement a classifier to detect offensive language (use the \"label\" column in the train and dev datasets). You could for example use a TF-IDF model with any classifier you like from sklearn. Your focus, before the laboratory, is to clearly understand LIME and the proposed dataset, as well as to bring your own classifier to the laboratory.\n",
    "2. **During the laboratory** (in groups): compare your classifiers and chose one or two to work with (e.g., select the best-performing ones, or those using different methods). Split into two sub-groups: one will use LIME to come-up with explanations for classifications. In particular, they will focus on missclassifications and try to explain those. Another group will select a definition of bias (from literature - can be from week 2 or any other literature you find) and verify whether your classifier(s) are biased wrt. different demgraphic dialects. For this task, use your classifier(s) on the “mini_demographic_dev.tsv” dataset, and assess bias by demographic group (see below for details). At the end of the laboratory, try to combine your work by using LIME to explain biased classifications.\n",
    "3. **After the laboratory** (in groups): wrap-up your work and write up your results and thoughts into a brief project report. Make sure to discuss the question of whether you think LIME is effective at explaining your classifier(s), whether you found bias in the classifier, and whether LIME explains biased classifications well (or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "*This dataset and text is taken with permission from the [Computational Ethics for NLP course, HW2](http://demo.clab.cs.cmu.edu/ethical_nlp2020/homeworks/hw2/hw2.html).*\n",
    "\n",
    "The primary data for this assignment is available in the dataset folder. **Please note that the data contains offensive or sensitive content, including profanity and racial slurs.**\n",
    "\n",
    "We provide data drawn from two sources. The first (files \"train.tsv\" and \"dev.tsv\") consists of tweets annotated for offensiveness taken from the [2019 SemEval task](https://competitions.codalab.org/competitions/20011) on offensive language detection. In the files \"train.tsv\" and \"dev.tsv\", the first column (text) contains the text of a tweet, the second column (label) contains an offensiveness label:\n",
    "\n",
    "* (NOT) Not Offensive - This post does not contain offense or profanity.\n",
    "* (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense\n",
    "\n",
    "The file “offenseval-annotation.txt” provides additional details on the annotation scheme.\n",
    "\n",
    "We additionally provide a data set of tweets proxy-labelled for race in the file titled “mini_demographic_dev.tsv”. This data is taken from the [TwitterAAE](http://slanglab.cs.umass.edu/TwitterAAE/) data set and uses posterior proportions of demographic topics as a proxy for racial dialect ([details](https://www.aclweb.org/anthology/D16-1120.pdf)). The first column (“text”) contains the text of the tweet, and the second column (“demographic”) contains a label: “AA” (for “African American”), “White”, “Hispanic”, or “Other”. For this assignment, we assume that no tweet in the TwitterAAE data set contains toxic language. Thus, any tweet in this file that is classified as toxic is a false positive.\n",
    "\n",
    "Finally, both development sets (“dev.tsv” and “mini_demographic_dev.tsv”) contain a column “perspective_score”, which contains a toxicity score. These scores were obtain using the [PerspectiveAPI tool](https://www.perspectiveapi.com/) released by Alphabet. This tool is intended to help “developers and publishers…give realtime feedback to commenters or help moderators do their job”\n",
    "\n",
    "In all data sets, user mentions have been replaced with the token @USER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk, sklearn\n",
    "\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/civility_data/train.tsv\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"dataset/civility_data/dev.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"dataset/civility_data/test.tsv\", sep=\"\\t\")\n",
    "df_demo = pd.read_csv(\"dataset/civility_data/mini_demographic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER You are an embarrassing citizen!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Seems hard to believe that you stood nex...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER @USER Wow !!! no wonder the Libera...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER And not all idiots grandstands lik...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Bring on the hypocrite gungrabber. MAGA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category\n",
       "0      @USER @USER You are an embarrassing citizen!!   OFF      TIN\n",
       "1  @USER Seems hard to believe that you stood nex...   OFF      TIN\n",
       "2  @USER @USER @USER Wow !!! no wonder the Libera...   OFF      TIN\n",
       "3  @USER @USER And not all idiots grandstands lik...   OFF      TIN\n",
       "4      @USER Bring on the hypocrite gungrabber. MAGA   OFF      TIN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>demographic</th>\n",
       "      <th>perspective_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People make mistakes. It takes a good person t...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only one on our road with power, but no cable ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.061435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love when baby's yawn I think it's so cute.</td>\n",
       "      <td>White</td>\n",
       "      <td>0.056817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theres so many hoes now that i actually think ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.503459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today is the day Adalynn Alexis will be here! ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.092183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text demographic  \\\n",
       "0  People make mistakes. It takes a good person t...       White   \n",
       "1  Only one on our road with power, but no cable ...       White   \n",
       "2      I love when baby's yawn I think it's so cute.       White   \n",
       "3  theres so many hoes now that i actually think ...       White   \n",
       "4  Today is the day Adalynn Alexis will be here! ...       White   \n",
       "\n",
       "   perspective_score  \n",
       "0           0.041031  \n",
       "1           0.061435  \n",
       "2           0.056817  \n",
       "3           0.503459  \n",
       "4           0.092183  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.77      0.93      0.84       884\n",
      "         OFF       0.75      0.44      0.56       440\n",
      "\n",
      "    accuracy                           0.77      1324\n",
      "   macro avg       0.76      0.68      0.70      1324\n",
      "weighted avg       0.76      0.77      0.75      1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def preprocess(df):\n",
    "    result = df.copy()\n",
    "\n",
    "    result['cleaned_text'] = result['text'].astype(str).str.lower()\n",
    "    result['cleaned_text'] = result['cleaned_text'].str.replace(r'@user\\s*', '', regex=True)\n",
    "\n",
    "    result['cleaned_text'] = result['cleaned_text'].str.replace(\n",
    "        r'[^a-z0-9\\s,.!?]', ' ', regex=True)\n",
    "    \n",
    "    result['cleaned_text'] = result['cleaned_text'].str.replace(\n",
    "        r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    return result[['cleaned_text', 'label']]\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_dev = preprocess(df_dev)\n",
    "\n",
    "X_train = df_train['cleaned_text']\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_dev = df_dev['cleaned_text']\n",
    "y_dev = df_dev['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(4,6),\n",
    "    min_df=5,\n",
    "    max_features=30000\n",
    ")\n",
    "\n",
    "X_train_t = vectorizer.fit_transform(X_train)\n",
    "X_dev_t = vectorizer.transform(X_dev)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=1)\n",
    "model.fit(X_train_t, y_train)\n",
    "y_pred = model.predict(X_dev_t)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to explain:\n",
      " the nose distracts from the news\n",
      "\n",
      "Random index:  789\n",
      "True label: OFF\n",
      "Predicted label: NOT\n",
      "\n",
      "LIME explanation:\n",
      "distracts: 0.037\n",
      "the: -0.033\n",
      "from: -0.012\n",
      "news: 0.008\n",
      "nose: -0.006\n"
     ]
    }
   ],
   "source": [
    "def predict_proba_lime(texts):\n",
    "    X = vectorizer.transform(texts)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "class_names = model.classes_\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "random_index = random.choice(np.where(y_dev != y_pred)[0])\n",
    "\n",
    "text_instance = X_dev.iloc[random_index]\n",
    "print('Text to explain:\\n', text_instance)\n",
    "\n",
    "true_label = y_dev.iloc[random_index]\n",
    "pred_label = y_pred[random_index]\n",
    "\n",
    "print('\\nRandom index: ', random_index)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', pred_label)\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    text_instance,\n",
    "    predict_proba_lime,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "print('\\nLIME explanation:')\n",
    "for feature, weight in exp.as_list():\n",
    "    print(f\"{feature}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A biased classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
