{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Civility in Communication\n",
    "\n",
    "The focus of this assignment will be on a) training a classifier to perform hate speech detection; b) use LIME to explain the classifier's behaviour; c) establish whether the classifier might be biased wrt. different demographic dialects.\n",
    "\n",
    "This assignment is divided into three parts:\n",
    "1. **Before the laboratory** (individually): read [LIME's paper](https://arxiv.org/abs/1602.04938) and understand how its Python implementation works: https://github.com/marcotcr/lime (docs: https://lime-ml.readthedocs.io/en/latest/index.html). Check these tutorials in particular: [1](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html) and [2](https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html). Furthermore, download the dataset, read its description below and make sure you understand it. Finally, implement a classifier to detect offensive language (use the \"label\" column in the train and dev datasets). You could for example use a TF-IDF model with any classifier you like from sklearn. Your focus, before the laboratory, is to clearly understand LIME and the proposed dataset, as well as to bring your own classifier to the laboratory.\n",
    "2. **During the laboratory** (in groups): compare your classifiers and chose one or two to work with (e.g., select the best-performing ones, or those using different methods). Split into two sub-groups: one will use LIME to come-up with explanations for classifications. In particular, they will focus on missclassifications and try to explain those. Another group will select a definition of bias (from literature - can be from week 2 or any other literature you find) and verify whether your classifier(s) are biased wrt. different demgraphic dialects. For this task, use your classifier(s) on the “mini_demographic_dev.tsv” dataset, and assess bias by demographic group (see below for details). At the end of the laboratory, try to combine your work by using LIME to explain biased classifications.\n",
    "3. **After the laboratory** (in groups): wrap-up your work and write up your results and thoughts into a brief project report. Make sure to discuss the question of whether you think LIME is effective at explaining your classifier(s), whether you found bias in the classifier, and whether LIME explains biased classifications well (or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "*This dataset and text is taken with permission from the [Computational Ethics for NLP course, HW2](http://demo.clab.cs.cmu.edu/ethical_nlp2020/homeworks/hw2/hw2.html).*\n",
    "\n",
    "The primary data for this assignment is available in the dataset folder. **Please note that the data contains offensive or sensitive content, including profanity and racial slurs.**\n",
    "\n",
    "We provide data drawn from two sources. The first (files \"train.tsv\" and \"dev.tsv\") consists of tweets annotated for offensiveness taken from the [2019 SemEval task](https://competitions.codalab.org/competitions/20011) on offensive language detection. In the files \"train.tsv\" and \"dev.tsv\", the first column (text) contains the text of a tweet, the second column (label) contains an offensiveness label:\n",
    "\n",
    "* (NOT) Not Offensive - This post does not contain offense or profanity.\n",
    "* (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense\n",
    "\n",
    "The file “offenseval-annotation.txt” provides additional details on the annotation scheme.\n",
    "\n",
    "We additionally provide a data set of tweets proxy-labelled for race in the file titled “mini_demographic_dev.tsv”. This data is taken from the [TwitterAAE](http://slanglab.cs.umass.edu/TwitterAAE/) data set and uses posterior proportions of demographic topics as a proxy for racial dialect ([details](https://www.aclweb.org/anthology/D16-1120.pdf)). The first column (“text”) contains the text of the tweet, and the second column (“demographic”) contains a label: “AA” (for “African American”), “White”, “Hispanic”, or “Other”. For this assignment, we assume that no tweet in the TwitterAAE data set contains toxic language. Thus, any tweet in this file that is classified as toxic is a false positive.\n",
    "\n",
    "Finally, both development sets (“dev.tsv” and “mini_demographic_dev.tsv”) contain a column “perspective_score”, which contains a toxicity score. These scores were obtain using the [PerspectiveAPI tool](https://www.perspectiveapi.com/) released by Alphabet. This tool is intended to help “developers and publishers…give realtime feedback to commenters or help moderators do their job”\n",
    "\n",
    "In all data sets, user mentions have been replaced with the token @USER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting patsy>=0.5.6\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/luka/.local/lib/python3.10/site-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.2 statsmodels-0.14.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk, sklearn\n",
    "\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/civility_data/train.tsv\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"dataset/civility_data/dev.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"dataset/civility_data/test.tsv\", sep=\"\\t\")\n",
    "df_demo = pd.read_csv(\"dataset/civility_data/mini_demographic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER You are an embarrassing citizen!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Seems hard to believe that you stood nex...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER @USER Wow !!! no wonder the Libera...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER And not all idiots grandstands lik...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Bring on the hypocrite gungrabber. MAGA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category\n",
       "0      @USER @USER You are an embarrassing citizen!!   OFF      TIN\n",
       "1  @USER Seems hard to believe that you stood nex...   OFF      TIN\n",
       "2  @USER @USER @USER Wow !!! no wonder the Libera...   OFF      TIN\n",
       "3  @USER @USER And not all idiots grandstands lik...   OFF      TIN\n",
       "4      @USER Bring on the hypocrite gungrabber. MAGA   OFF      TIN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>demographic</th>\n",
       "      <th>perspective_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People make mistakes. It takes a good person t...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only one on our road with power, but no cable ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.061435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love when baby's yawn I think it's so cute.</td>\n",
       "      <td>White</td>\n",
       "      <td>0.056817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theres so many hoes now that i actually think ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.503459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today is the day Adalynn Alexis will be here! ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.092183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text demographic  \\\n",
       "0  People make mistakes. It takes a good person t...       White   \n",
       "1  Only one on our road with power, but no cable ...       White   \n",
       "2      I love when baby's yawn I think it's so cute.       White   \n",
       "3  theres so many hoes now that i actually think ...       White   \n",
       "4  Today is the day Adalynn Alexis will be here! ...       White   \n",
       "\n",
       "   perspective_score  \n",
       "0           0.041031  \n",
       "1           0.061435  \n",
       "2           0.056817  \n",
       "3           0.503459  \n",
       "4           0.092183  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a text classification model using character-level (`analyzer='char_wb'`) TF-IDF features (with 4–6 character n-grams; `ngram_range=(4,6)`), removing very rare n-grams that appear in fewer than 5 documents (`min_df=5`). A Random Forest classifier is then fitted on the training data, used to predict labels for the dev set, and evaluated using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.77      0.93      0.84       884\n",
      "         OFF       0.76      0.44      0.55       440\n",
      "\n",
      "    accuracy                           0.77      1324\n",
      "   macro avg       0.77      0.68      0.70      1324\n",
      "weighted avg       0.77      0.77      0.75      1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split training data into features and target\n",
    "X_train = df_train['text']\n",
    "y_train = df_train['label']\n",
    "\n",
    "# Split development data into features and target\n",
    "X_dev = df_dev['text']\n",
    "y_dev = df_dev['label']\n",
    "\n",
    "# Create a vectorizer using character n-grams with length 4-6\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(4,6),\n",
    "    min_df=5,\n",
    "    max_features=300000\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the training data and transform development text\n",
    "X_train_t = vectorizer.fit_transform(X_train)\n",
    "X_dev_t = vectorizer.transform(X_dev)\n",
    "\n",
    "# Create a random forest classifier with 200 trees\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=1)\n",
    "\n",
    "# Train the model using the TF-IDF training data and predict development labels \n",
    "model.fit(X_train_t, y_train)\n",
    "y_pred = model.predict(X_dev_t)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to explain:\n",
      " *a shooting happens in a country with gun control laws for the first time in literally decades*  Y'all: BUT THE GUN LAWS SHOULD'VE PREVENTED THIS UNGA BUNGA THIS IS WHY GUN CONTROL SUCKS BET YOU DUMMIES WISH YOU HAD GUNS  *meanwhile another school shooting happens in America*\n",
      "\n",
      "Random index:  994\n",
      "True label: NOT\n",
      "Predicted label: OFF\n",
      "\n",
      "LIME explanation:\n",
      "SUCKS: 0.299\n",
      "happens: -0.050\n",
      "shooting: -0.047\n",
      "PREVENTED: 0.043\n",
      "SHOULD: -0.016\n",
      "CONTROL: -0.016\n",
      "control: -0.014\n",
      "decades: 0.013\n",
      "literally: -0.013\n",
      "country: 0.010\n"
     ]
    }
   ],
   "source": [
    "# Function to predict probabilities for LIME\n",
    "def predict_proba_lime(texts):\n",
    "    X = vectorizer.transform(texts)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "class_names = model.classes_\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Select a random misclassified instance\n",
    "random_index = random.choice(np.where(y_dev != y_pred)[0])\n",
    "# For the LIME explanation (comment this in for random): \n",
    "random_index = 994\n",
    "\n",
    "text_instance = X_dev.iloc[random_index]\n",
    "print('Text to explain:\\n', text_instance)\n",
    "\n",
    "true_label = y_dev.iloc[random_index]\n",
    "pred_label = y_pred[random_index]\n",
    "\n",
    "print('\\nRandom index: ', random_index)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', pred_label)\n",
    "\n",
    "# Generate LIME explanation\n",
    "exp = explainer.explain_instance(\n",
    "    text_instance,\n",
    "    predict_proba_lime,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "# Display the explanation, which includes words and their weights\n",
    "print('\\nLIME explanation:')\n",
    "for feature, weight in exp.as_list():\n",
    "    print(f\"{feature}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying LIME to the misclassifications, we can see how the different words contribute to the misclassification. The example above shows the text which is misclassified as offensive where the true label is actually not offensive. The Lime explanation shows that word 'SUCKS' is more related to a offensive prediction, because of its positive weight. In particular, the word SUCKS is likely associated with negative contexts in the training data, which causes the model to predict offensive. At the same time, other words such as 'shooting' receive a negative weight and therefore slightly push the prediction toward the not offensive class, but this effect is probably much smaller. So in this case, the model chooses to predict offensive, based on the negative word 'SUCKS'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best word: sucks\n",
      "Removed feature: \"sucks\"\n",
      "Removed feature: \" sucks\"\n",
      "Removed feature: \"sucks \"\n",
      "\n",
      "Original prediction:\n",
      "  class = OFF, probability = 0.5800\n",
      "\n",
      "Prediction removing best word:\n",
      "  class = NOT, probability = 0.4800\n",
      "\n",
      "Difference in probability: -0.09999999999999998\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Remove the most important feature ----\n",
    "\n",
    "# Get the feature weights from LIME explanation\n",
    "feature_weights = exp.as_list()\n",
    "feature_weights = sorted(feature_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Identify the best word (most impactful feature)\n",
    "best_word = feature_weights[0][0].lower()\n",
    "print(f\"Best word: {best_word}\")\n",
    "\n",
    "tmp = vectorizer.transform([text_instance]).copy()\n",
    "\n",
    "# Consider different spacing variants of the best word\n",
    "variants = [\n",
    "    best_word,\n",
    "    f\" {best_word}\",\n",
    "    f\"{best_word} \"\n",
    "]\n",
    "\n",
    "# Remove the best word from the feature vector\n",
    "for v in variants:\n",
    "    if v in vectorizer.vocabulary_:\n",
    "        print(f'Removed feature: \"{v}\"')\n",
    "        tmp[0, vectorizer.vocabulary_[v]] = 0\n",
    "\n",
    "# ---- Predictions ----\n",
    "orig_vec = vectorizer.transform([text_instance])\n",
    "\n",
    "orig_proba = model.predict_proba(orig_vec)[0, 1]\n",
    "new_proba = model.predict_proba(tmp)[0, 1]\n",
    "\n",
    "orig_pred = model.predict(orig_vec)[0]\n",
    "new_pred = model.predict(tmp)[0]\n",
    "\n",
    "# Print the probabilities of the original and modified instances\n",
    "print('\\nOriginal prediction:')\n",
    "print(f'  class = {orig_pred}, probability = {orig_proba:.4f}\\n')\n",
    "print('Prediction removing best word:')\n",
    "print(f'  class = {new_pred}, probability = {new_proba:.4f}\\n')\n",
    "print('Difference in probability:', new_proba - orig_proba)\n",
    "\n",
    "# Visualize the LIME explanation\n",
    "fig = exp.as_pyplot_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we got the LIME explanation, we tried to remove the word with the highest weight according to LIME. Then we predict the text again and we observe a clear drop in the predicted probability for the offensive class, and in this case even a change in the predicted label from offensive to not offensive. This also suggest that the word 'SUCKS' plays a strong local role in the model’s decision for this particular example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A biased classifier?\n",
    "We want to check whether our logistic regression classifier shows **demographic bias**\n",
    "when predicting \"OFF\" (offensive) on a dataset with various tweets with different **demographic dialects** in which **all tweets are labeled as \"NOT\" (not offensive)**.\n",
    "\n",
    "In other words: we are looking at **false positive rate (FPR)** across different demographics.\n",
    "\n",
    "High difference in FPR between groups may indicate demographic bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier (Logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       1.00      0.76      0.86      5072\n",
      "         OFF       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76      5072\n",
      "   macro avg       0.50      0.38      0.43      5072\n",
      "weighted avg       1.00      0.76      0.86      5072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df_demo = df_demo.reset_index(drop=True)\n",
    "\n",
    "# All true labels in this set are 'NOT'\n",
    "X_dev = df_demo['text']\n",
    "y_dev = ['NOT'] * len(df_demo)\n",
    "\n",
    "X_dev_t = vectorizer.transform(X_dev)\n",
    "\n",
    "# Model, class_weight = balanced helps when data is imbalanced\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced', \n",
    "    random_state=201\n",
    ")\n",
    "# Fit model and predict on the data to get the predicted labels\n",
    "model.fit(X_train_t, y_train)\n",
    "y_pred = model.predict(X_dev_t)\n",
    "print(classification_report(y_dev, y_pred))\n",
    "\n",
    "# The predicted labels to which we will compare the true labels (all \"NOT\")\n",
    "df_demo[\"pred_label\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify if the classifier is biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution by counts\n",
      "demographic\n",
      "White       4235\n",
      "Hispanic     335\n",
      "AA           332\n",
      "Other        170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution by percentages\n",
      "demographic\n",
      "White       83.50\n",
      "Hispanic     6.60\n",
      "AA           6.55\n",
      "Other        3.35\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quick distribution check of the counts between all demographics to see difference in counts between groups\n",
    "print(\"Distribution by counts\")\n",
    "print(df_demo['demographic'].value_counts())\n",
    "print()\n",
    "print(\"Distribution by percentages\")\n",
    "print((df_demo['demographic'].value_counts(normalize=True) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives (FP) by demographic:\n",
      "White   : Count = 4235 | FP = 1019 | FPR 24.06% | [22.80%, 25.37%]\n",
      "Hispanic: Count =  335 | FP =  98 | FPR 29.25% | [24.64%, 34.34%]\n",
      "AA      : Count =  332 | FP = 115 | FPR 34.64% | [29.72%, 39.91%]\n",
      "Other   : Count =  170 | FP =   6 | FPR 3.53% | [1.63%, 7.49%]\n"
     ]
    }
   ],
   "source": [
    "print(\"False positives (FP) by demographic:\")\n",
    "for group in df_demo['demographic'].unique():\n",
    "    # Select rows belonging to current demographic group and get the # of rows\n",
    "    n = len(df_demo[df_demo['demographic'] == group])\n",
    "    \n",
    "    # How many times did we predict OFF? (these are all false positives!)\n",
    "    fp = (df_demo[df_demo['demographic'] == group]['pred_label'] == 'OFF').sum()\n",
    "    \n",
    "    ci_low, ci_high = proportion_confint(count=fp, nobs=n, alpha=0.05, method='wilson')\n",
    "\n",
    "    print(f\"{group:8}: Count = {n:4} | FP = {fp:3} | FPR {fp/n:.2%} | [{ci_low:.2%}, {ci_high:.2%}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results\n",
    "- **FPR** = False Positive Rate = % of non-offensive texts that were wrongly classified as offensive\n",
    "- In an ideal world. FPR should be **similar** across all demographic groups\n",
    "- Big differences (especially >5–10 percentage points) usually indicate bias\n",
    "\n",
    "The results indicate that the model shows large variation in FPR between different demographic dialects. Tweets associated with African American (AA) dialects show the highest false positive rate with being seen ~1,44x more probable as offensive compared to a White dialect and ~1,18x to a Hispanic dialect\n",
    "\n",
    "The 95% confidence intervals also show no overlap between AA and White dialects thus reinforcing the fact that there might be strong bias in our classifier. Hispanic dialects also seem to have a higher probability to be seen as offensive compared to a white dialect, but the difference is smaller than a AA dialect. When we also take a look at the confidence intervals we do see small overlap with a white dialect indicating that the bias between White and Hispanic dialects are smaller than that of a AA dialect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to explain:\n",
      " This GCF shit is getting on my nerves\n",
      "\n",
      "Random index:  1686\n",
      "True label: NOT\n",
      "Predicted label: OFF\n",
      "\n",
      "LIME explanation:\n",
      "shit: 0.401\n",
      "This: 0.050\n",
      "getting: -0.020\n",
      "nerves: 0.016\n",
      "is: 0.008\n",
      "on: -0.008\n",
      "my: -0.004\n",
      "GCF: 0.002\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select all rows with demographic status AA and offensive target label\n",
    "aa_fp = df_demo[\n",
    "    (df_demo['demographic'] == 'AA') &\n",
    "    (df_demo['pred_label'] == 'OFF')\n",
    "]\n",
    "\n",
    "# Select a random misclassified instance\n",
    "random_row = aa_fp.sample(n=1, random_state=None)\n",
    "random_index = random_row.index[0]\n",
    "# For the LIME explanation (comment this in for random):\n",
    "random_index = 1686\n",
    "\n",
    "text_instance = X_dev.iloc[random_index]\n",
    "print('Text to explain:\\n', text_instance)\n",
    "\n",
    "true_label = \"NOT\"\n",
    "pred_label = y_pred[random_index]\n",
    "\n",
    "print('\\nRandom index: ', random_index)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', pred_label)\n",
    "\n",
    "# Generate LIME explanation\n",
    "exp = explainer.explain_instance(\n",
    "    text_instance,\n",
    "    predict_proba_lime,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "# Display the explanation, which includes words and their weights\n",
    "print('\\nLIME explanation:')\n",
    "for feature, weight in exp.as_list():\n",
    "    print(f\"{feature}: {weight:.3f}\")\n",
    "    \n",
    "fig = exp.as_pyplot_figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying LIME to misclassified examples, we can see how individual words influence the model’s predictions. In the example above, the text is incorrectly classified as offensive even though the true label is not offensive. The LIME explanation shows that the word **'shit'** has a strong positive weight, pushing the model toward an offensive prediction. This likely reflects its frequent association with offensive contexts in the training data, even though here it is not directed at anyone in this case. This is also a good example of a limitation of this classifier, it doesnt take the whole context into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
