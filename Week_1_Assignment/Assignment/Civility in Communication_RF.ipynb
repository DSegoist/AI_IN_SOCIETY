{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Civility in Communication\n",
    "\n",
    "The focus of this assignment will be on a) training a classifier to perform hate speech detection; b) use LIME to explain the classifier's behaviour; c) establish whether the classifier might be biased wrt. different demographic dialects.\n",
    "\n",
    "This assignment is divided into three parts:\n",
    "1. **Before the laboratory** (individually): read [LIME's paper](https://arxiv.org/abs/1602.04938) and understand how its Python implementation works: https://github.com/marcotcr/lime (docs: https://lime-ml.readthedocs.io/en/latest/index.html). Check these tutorials in particular: [1](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html) and [2](https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html). Furthermore, download the dataset, read its description below and make sure you understand it. Finally, implement a classifier to detect offensive language (use the \"label\" column in the train and dev datasets). You could for example use a TF-IDF model with any classifier you like from sklearn. Your focus, before the laboratory, is to clearly understand LIME and the proposed dataset, as well as to bring your own classifier to the laboratory.\n",
    "2. **During the laboratory** (in groups): compare your classifiers and chose one or two to work with (e.g., select the best-performing ones, or those using different methods). Split into two sub-groups: one will use LIME to come-up with explanations for classifications. In particular, they will focus on missclassifications and try to explain those. Another group will select a definition of bias (from literature - can be from week 2 or any other literature you find) and verify whether your classifier(s) are biased wrt. different demgraphic dialects. For this task, use your classifier(s) on the “mini_demographic_dev.tsv” dataset, and assess bias by demographic group (see below for details). At the end of the laboratory, try to combine your work by using LIME to explain biased classifications.\n",
    "3. **After the laboratory** (in groups): wrap-up your work and write up your results and thoughts into a brief project report. Make sure to discuss the question of whether you think LIME is effective at explaining your classifier(s), whether you found bias in the classifier, and whether LIME explains biased classifications well (or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "*This dataset and text is taken with permission from the [Computational Ethics for NLP course, HW2](http://demo.clab.cs.cmu.edu/ethical_nlp2020/homeworks/hw2/hw2.html).*\n",
    "\n",
    "The primary data for this assignment is available in the dataset folder. **Please note that the data contains offensive or sensitive content, including profanity and racial slurs.**\n",
    "\n",
    "We provide data drawn from two sources. The first (files \"train.tsv\" and \"dev.tsv\") consists of tweets annotated for offensiveness taken from the [2019 SemEval task](https://competitions.codalab.org/competitions/20011) on offensive language detection. In the files \"train.tsv\" and \"dev.tsv\", the first column (text) contains the text of a tweet, the second column (label) contains an offensiveness label:\n",
    "\n",
    "* (NOT) Not Offensive - This post does not contain offense or profanity.\n",
    "* (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense\n",
    "\n",
    "The file “offenseval-annotation.txt” provides additional details on the annotation scheme.\n",
    "\n",
    "We additionally provide a data set of tweets proxy-labelled for race in the file titled “mini_demographic_dev.tsv”. This data is taken from the [TwitterAAE](http://slanglab.cs.umass.edu/TwitterAAE/) data set and uses posterior proportions of demographic topics as a proxy for racial dialect ([details](https://www.aclweb.org/anthology/D16-1120.pdf)). The first column (“text”) contains the text of the tweet, and the second column (“demographic”) contains a label: “AA” (for “African American”), “White”, “Hispanic”, or “Other”. For this assignment, we assume that no tweet in the TwitterAAE data set contains toxic language. Thus, any tweet in this file that is classified as toxic is a false positive.\n",
    "\n",
    "Finally, both development sets (“dev.tsv” and “mini_demographic_dev.tsv”) contain a column “perspective_score”, which contains a toxicity score. These scores were obtain using the [PerspectiveAPI tool](https://www.perspectiveapi.com/) released by Alphabet. This tool is intended to help “developers and publishers…give realtime feedback to commenters or help moderators do their job”\n",
    "\n",
    "In all data sets, user mentions have been replaced with the token @USER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk, sklearn\n",
    "\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/civility_data/train.tsv\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"dataset/civility_data/dev.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"dataset/civility_data/test.tsv\", sep=\"\\t\")\n",
    "df_demo = pd.read_csv(\"dataset/civility_data/mini_demographic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER You are an embarrassing citizen!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Seems hard to believe that you stood nex...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER @USER Wow !!! no wonder the Libera...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER And not all idiots grandstands lik...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Bring on the hypocrite gungrabber. MAGA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category\n",
       "0      @USER @USER You are an embarrassing citizen!!   OFF      TIN\n",
       "1  @USER Seems hard to believe that you stood nex...   OFF      TIN\n",
       "2  @USER @USER @USER Wow !!! no wonder the Libera...   OFF      TIN\n",
       "3  @USER @USER And not all idiots grandstands lik...   OFF      TIN\n",
       "4      @USER Bring on the hypocrite gungrabber. MAGA   OFF      TIN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>demographic</th>\n",
       "      <th>perspective_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People make mistakes. It takes a good person t...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only one on our road with power, but no cable ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.061435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love when baby's yawn I think it's so cute.</td>\n",
       "      <td>White</td>\n",
       "      <td>0.056817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theres so many hoes now that i actually think ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.503459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today is the day Adalynn Alexis will be here! ...</td>\n",
       "      <td>White</td>\n",
       "      <td>0.092183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text demographic  \\\n",
       "0  People make mistakes. It takes a good person t...       White   \n",
       "1  Only one on our road with power, but no cable ...       White   \n",
       "2      I love when baby's yawn I think it's so cute.       White   \n",
       "3  theres so many hoes now that i actually think ...       White   \n",
       "4  Today is the day Adalynn Alexis will be here! ...       White   \n",
       "\n",
       "   perspective_score  \n",
       "0           0.041031  \n",
       "1           0.061435  \n",
       "2           0.056817  \n",
       "3           0.503459  \n",
       "4           0.092183  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5422/4083539445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = df_train['text']\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_dev = df_dev['text']\n",
    "y_dev = df_dev['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(4,6),\n",
    "    min_df=5,\n",
    "    max_features=30000\n",
    ")\n",
    "\n",
    "X_train_t = vectorizer.fit_transform(X_train)\n",
    "X_dev_t = vectorizer.transform(X_dev)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=1)\n",
    "model.fit(X_train_t, y_train)\n",
    "y_pred = model.predict(X_dev_t)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to explain:\n",
      " @USER Liberals are all Kookoo !!!\n",
      "\n",
      "Random index:  5\n",
      "True label: OFF\n",
      "Predicted label: NOT\n",
      "\n",
      "LIME explanation:\n",
      "Liberals: 0.104\n",
      "are: 0.069\n",
      "USER: -0.014\n",
      "all: 0.005\n",
      "Kookoo: -0.003\n"
     ]
    }
   ],
   "source": [
    "def predict_proba_lime(texts):\n",
    "    X = vectorizer.transform(texts)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "class_names = model.classes_\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "random_index = random.choice(np.where(y_dev != y_pred)[0])\n",
    "\n",
    "text_instance = X_dev.iloc[random_index]\n",
    "print('Text to explain:\\n', text_instance)\n",
    "\n",
    "true_label = y_dev.iloc[random_index]\n",
    "pred_label = y_pred[random_index]\n",
    "\n",
    "print('\\nRandom index: ', random_index)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', pred_label)\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    text_instance,\n",
    "    predict_proba_lime,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "print('\\nLIME explanation:')\n",
    "for feature, weight in exp.as_list():\n",
    "    print(f\"{feature}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best word: liberals\n",
      "\n",
      "Original prediction:\n",
      "  class = NOT, probability = 0.1800\n",
      "\n",
      "Prediction removing best word:\n",
      "  class = NOT, probability = 0.1800\n",
      "\n",
      "Difference in probability: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_weights = exp.as_list()\n",
    "feature_weights = sorted(feature_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "best_word = feature_weights[0][0].lower()\n",
    "print(f\"Best word: {best_word}\")\n",
    "\n",
    "tmp = vectorizer.transform([text_instance]).copy()\n",
    "\n",
    "variants = [\n",
    "    best_word,\n",
    "    f\" {best_word}\",\n",
    "    f\"{best_word} \"\n",
    "]\n",
    "\n",
    "for v in variants:\n",
    "    if v in vectorizer.vocabulary_:\n",
    "        print(f'Removed feature: \"{v}\"')\n",
    "        tmp[0, vectorizer.vocabulary_[v]] = 0\n",
    "\n",
    "# ---- Predictions ----\n",
    "orig_vec = vectorizer.transform([text_instance])\n",
    "\n",
    "orig_proba = model.predict_proba(orig_vec)[0, 1]\n",
    "new_proba = model.predict_proba(tmp)[0, 1]\n",
    "\n",
    "orig_pred = model.predict(orig_vec)[0]\n",
    "new_pred = model.predict(tmp)[0]\n",
    "\n",
    "print('\\nOriginal prediction:')\n",
    "print(f'  class = {orig_pred}, probability = {orig_proba:.4f}\\n')\n",
    "print('Prediction removing best word:')\n",
    "print(f'  class = {new_pred}, probability = {new_proba:.4f}\\n')\n",
    "print('Difference in probability:', new_proba - orig_proba)\n",
    "\n",
    "fig = exp.as_pyplot_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A biased classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier (Logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       1.00      0.76      0.87      5072\n",
      "         OFF       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76      5072\n",
      "   macro avg       0.50      0.38      0.43      5072\n",
      "weighted avg       1.00      0.76      0.87      5072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_dev = df_demo['text']\n",
    "y_dev = ['NOT'] * len(df_demo)\n",
    "\n",
    "X_dev_t = vectorizer.transform(X_dev)\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=201\n",
    ")\n",
    "model.fit(X_train_t, y_train)\n",
    "y_dev_pred = model.predict(X_dev_t)\n",
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify if the classifier is biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution by counts\n",
      "demographic\n",
      "White       4235\n",
      "Hispanic     335\n",
      "AA           332\n",
      "Other        170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution by percentages\n",
      "demographic\n",
      "White       83.50\n",
      "Hispanic     6.60\n",
      "AA           6.55\n",
      "Other        3.35\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution by counts\")\n",
    "print(df_demo['demographic'].value_counts())\n",
    "print()\n",
    "print(\"Distribution by percentages\")\n",
    "print((df_demo['demographic'].value_counts(normalize=True) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess functie is nog niet generaliserend dus skip ik ff\n",
    "x_demo = df_demo[\"text\"]\n",
    "x_demo_tfidf = vectorizer.transform(x_demo)\n",
    "\n",
    "y_pred_demo = model.predict(x_demo_tfidf)\n",
    "df_demo[\"pred_label\"] = y_pred_demo\n",
    "# print(df_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives (fp) by demographic:\n",
      "White   : count = 4235 | fp = 413 | fp_rate 9.75%\n",
      "Hispanic: count =  335 | fp =  41 | fp_rate 12.24%\n",
      "AA      : count =  332 | fp =  72 | fp_rate 21.69%\n",
      "Other   : count =  170 | fp =   1 | fp_rate 0.59%\n"
     ]
    }
   ],
   "source": [
    "print(\"False positives (fp) by demographic:\")\n",
    "for group in df_demo['demographic'].unique():\n",
    "    n = len(df_demo[df_demo['demographic'] == group])\n",
    "    fp = (df_demo[df_demo['demographic'] == group]['pred_label'] == 'OFF').sum()\n",
    "\n",
    "    print(f\"{group:8}: count = {n:4} | fp = {fp:3} | fp_rate {fp/n:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
